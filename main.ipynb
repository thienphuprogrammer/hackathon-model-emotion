{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image_array = cv2.imread('AffectNet/train/0/image0000006.jpg', cv2.IMREAD_GRAYSCALE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image_array.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.imshow(image_array)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DATA_DIR = 'AffectNet/'\n",
    "CATEGORIES = ['train', 'val', 'test']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CLASSES = ['0', '1', '2', '3', '4', '5', '6', '7']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for categoy in CATEGORIES:\n",
    "    for class_name in CLASSES:\n",
    "        path = os.path.join(DATA_DIR, categoy, class_name)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path, img))\n",
    "            plt.imshow(img_array, cmap='gray')\n",
    "            plt.show()\n",
    "            break\n",
    "        break\n",
    "    break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image_size = 224\n",
    "image_array = cv2.resize(image_array, (image_size, image_size))\n",
    "plt.imshow(image_array, cmap='gray')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image_array.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all the images and convertin them to array"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def data_generator(data_dir, image_size=(224, 224), batch_size=32):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'train'),\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse',\n",
    "    )\n",
    "\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'val'),\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse',\n",
    "    )\n",
    "\n",
    "    test_gen = datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'test'),\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse'\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen, test_gen"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "image_size = (224, 224)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "batch_size = 32"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_gen, val_gen, test_gen = data_generator(DATA_DIR, image_size=image_size, batch_size=batch_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_gen.class_indices"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning model for training - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Activation # type: ignore\n",
    "from tensorflow.keras.models import Model  # type: ignore"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%pip install tensorflow-gpu"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_input = model.input"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_input"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "base_output = model.layers[-2].output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = base_output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(64)(x)\n",
    "x = Activation('relu')(x)\n",
    "predictions = Dense(train_gen.num_classes, activation='softmax')(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "new_model = Model(inputs=base_input, outputs=predictions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "new_model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "new_model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(learning_rate=0.0001))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Huấn luyện mô hình\n",
    "new_model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_gen.samples // batch_size,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_gen.samples // batch_size,\n",
    "    epochs=100\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# save the model\n",
    "new_model.save('emotion_model.h5')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov9-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
